{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1882037,"sourceType":"datasetVersion","datasetId":1120859}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ndf = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:28.461414Z","iopub.execute_input":"2025-06-19T10:31:28.462143Z","iopub.status.idle":"2025-06-19T10:31:28.857382Z","shell.execute_reply.started":"2025-06-19T10:31:28.462110Z","shell.execute_reply":"2025-06-19T10:31:28.856628Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**The following block of code performs One-Hot Encoding on a set of categorical features in the dataset using scikit-learn's OneHotEncoder.**\n\n## OneHotEncoder:\n- It is a tool from the ```sklearn.preprocessing``` library.\n- It converts categorical arguements/values into 0s or 1s\n- At a time, only a particular value is 1 or 'hot'\n- This encodes a set of values (eg. strings) into numerical data which helps models learn, train and test\n\n### How it all Encoding works:\n- First, we define the columns we want to encode into 0s and 1s\n- We then pass them to OneHotEncoder's ```fit_transform``` function. Each value is converted into an array of 0s and a single 1, which represents what that is.\n- For example, if there are 3 unique values in a column such as ```[Male, Female, Others]```. Then the encoding for ```Male``` would be ```[1, 0, 0]```. So only the ```Male``` value is hot, and the others aren't.\n- Similarly for ```Female``` the encoding would be ```[0, 1, 0]``` and so on\n- The ```fit_transform``` function results in a sparse matrix, which is then converted to a dense one using ```toarray()``` function.\n- The ```get_feature_names_out``` adds new columns to the dataset, with values corresponding to the encoded one\n- Finally, all these are added back to the dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nkat = [\"gender\", \"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\"]\nohe = OneHotEncoder()\nfeature = ohe.fit_transform(df[kat]).toarray()\nsut = ohe.get_feature_names_out(kat)\ndf[sut] = feature\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:28.858856Z","iopub.execute_input":"2025-06-19T10:31:28.859228Z","iopub.status.idle":"2025-06-19T10:31:28.889364Z","shell.execute_reply.started":"2025-06-19T10:31:28.859207Z","shell.execute_reply":"2025-06-19T10:31:28.888636Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Now we drop all null values across the ```bmi```, the old columns which are now OneHotEncoded, and the ```id``` column since it's irrelevant to our analysis. ","metadata":{}},{"cell_type":"code","source":"df.dropna(subset=['bmi'], inplace=True)\ndf = df.drop(columns=kat)\ndf = df.drop(columns=[\"id\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:28.890534Z","iopub.execute_input":"2025-06-19T10:31:28.890802Z","iopub.status.idle":"2025-06-19T10:31:28.902682Z","shell.execute_reply.started":"2025-06-19T10:31:28.890781Z","shell.execute_reply":"2025-06-19T10:31:28.901946Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Decision Tree Classifier:\n\n**How It Works:**\n\nThe algorithm splits the dataset into subsets based on the value of input features.\n\nIt continues splitting recursively until it reaches a stopping condition (e.g., max depth, pure leaf, or minimum samples).\n\nAt each node, it selects the best feature and threshold that results in the highest information gain or lowest impurity.\n\n1. **Impurity Measures**: *Used to determine the quality of a split*\n\n    - Gini Impurity (default): *A measure of how pure a node is, i.e, how many instances of different classes does it possess*\n\n    $$ G = 1 - \\sum_{i=1}^C p_i^2$$\n     \n    - Entropy (used in information gain): *The higher the entropy, the more mixed the node*\n    \n    $$\n    H = - \\sum_{i=1}^C p_i \\log_2 p_i\n    $$\n\n2. **Information Gain**: *The reduction in impurity before and after a split*\n\n    $$ Gain = H_{\\text {parent}} - \\sum{}\\frac{n_i}{n} H_i $$ \n\n3. **Sample Splitting**: *This is done to increase the purity of a node. Nodes are split based on a certain critera (eg: ```age <= 50```) so as to produce the purest child node. This process grows the tree recursively. This is done based on certain strategies. At each step, the best possbile (optimal) or a random strategy is chosen. Choosing the best possible at each step can cause overfitting.*\n \n**Some Common Hyperparameters**\n| *Parameter*        | *Description*                                                   |\n|----------------------|-------------------------------------------------------------------|\n| `criterion`          | Function to measure split quality: `'gini'` or `'entropy'`       |\n| `max_depth`          | Maximum depth of the tree                                         |\n| `min_samples_split`  | Minimum number of samples required to split an internal node     |\n| `min_samples_leaf`   | Minimum number of samples required to be at a leaf node          |\n| `max_features`       | Number of features to consider when looking for the best split   |\n| `splitter`           | Strategy used to choose the split: `'best'` or `'random'`        |\n","metadata":{}},{"cell_type":"markdown","source":"### Now, we split the data into inputs and output. The inputs are all other columns apart from the stroke, while the output is the stroke column itself.\n\n### After this, the inputs and outputs are split into training and testing sets.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score, accuracy_score\n\ny = df[\"stroke\"]\nx = df.drop(columns=[\"stroke\"])\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, train_size=0.8)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:28.903665Z","iopub.execute_input":"2025-06-19T10:31:28.903966Z","iopub.status.idle":"2025-06-19T10:31:29.252845Z","shell.execute_reply.started":"2025-06-19T10:31:28.903944Z","shell.execute_reply":"2025-06-19T10:31:29.252191Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### The model is now trained","metadata":{}},{"cell_type":"code","source":"tree = DecisionTreeClassifier()\nmodel = tree.fit(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:29.255275Z","iopub.execute_input":"2025-06-19T10:31:29.255729Z","iopub.status.idle":"2025-06-19T10:31:29.274314Z","shell.execute_reply.started":"2025-06-19T10:31:29.255703Z","shell.execute_reply":"2025-06-19T10:31:29.273658Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### F1 Score:\n\n*It is the harmonic mean of precision and recall, combining both into a single number that balances the two*\n\n$$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n\n*where,*\n\n$$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $$\n\n$$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} $$\n","metadata":{}},{"cell_type":"markdown","source":"$$\n\\text{F1}_{\\text{weighted}} = \\sum_{i=1}^{C} \\frac{n_i}{n} \\cdot \\text{F1}_i\n$$\n\n$$\n\\begin{aligned}\nC &= \\text{Number of classes} \\\\\nn_i &= \\text{Number of true instances for class } i \\\\\nn &= \\text{Total number of samples} \\\\\n\\text{F1}_i &= \\text{F1 score for class } i\n\\end{aligned}\n$$","metadata":{}},{"cell_type":"markdown","source":"### Accuracy Score\n\n$$\n\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} = \\frac{TP + TN}{TP + TN + FP + FN}\n$$\n\n$$\n\\begin{aligned}\nTP &= \\text{True Positives} \\\\\nTN &= \\text{True Negatives} \\\\\nFP &= \\text{False Positives} \\\\\nFN &= \\text{False Negatives}\n\\end{aligned}\n$$\n","metadata":{}},{"cell_type":"markdown","source":"\n\n### `classification_report` (scikit-learn)\n\nThe `classification_report` function prints key metrics for evaluating a classification model:\n\n* **Precision**: Accuracy of positive predictions\n* **Recall**: Ability to find all positive samples\n* **F1 Score**: Harmonic mean of precision & recall\n* **Support**: Number of true samples in each class\n","metadata":{}},{"cell_type":"code","source":"y_pred_tree = model.predict(x_test)\n\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report\n\nprint(\"Weighted F1 score: \", f1_score(y_test, y_pred_tree, average = 'weighted'))\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred_tree))\nprint(classification_report(y_test, y_pred_tree))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:29.275027Z","iopub.execute_input":"2025-06-19T10:31:29.275260Z","iopub.status.idle":"2025-06-19T10:31:29.292023Z","shell.execute_reply.started":"2025-06-19T10:31:29.275240Z","shell.execute_reply":"2025-06-19T10:31:29.291298Z"}},"outputs":[{"name":"stdout","text":"Weighted F1 score:  0.9132676560974813\nAccuracy score:  0.9164969450101833\n              precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96       929\n           1       0.18      0.15      0.16        53\n\n    accuracy                           0.92       982\n   macro avg       0.56      0.56      0.56       982\nweighted avg       0.91      0.92      0.91       982\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## GridSearchCV\n\n`GridSearchCV` is a tool in `scikit-learn` used for **exhaustive hyperparameter tuning**. It  searches through a **grid of specified hyperparameter values** and evaluates model performance using **cross-validation**.\n\n\n### What It Does\n\n`GridSearchCV` performs:\n\n1. **Model training** on multiple combinations of hyperparameters.\n2. **Cross-validation** for each combination.\n3. **Selection** of the best parameters based on a scoring metric (e.g., accuracy, F1 score).\n\n\n### Accuracy of Cross-Validation\n\nIf using `k`-fold cross-validation:\n\n\n$$\n\\text{CV Accuracy} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{Accuracy}_i\n$$\n\n\nWhere $\\text{Accuracy}_i$ is the accuracy on the $i$-th validation fold.\n\n\n\n### Common Parameters\n\n| **Parameter**        | **Description**                                                             |\n| -------------------- | --------------------------------------------------------------------------- |\n| `estimator`          | The model (e.g., `SVC()`, `RandomForestClassifier()`)                       |\n| `param_grid`         | Dictionary or list of dictionaries with hyperparameters to try              |\n| `scoring`            | Metric to optimize (`'accuracy'`, `'f1'`, `'neg_mean_squared_error'`, etc.) |\n| `cv`                 | Number of cross-validation folds (e.g., `cv=5`)                             |\n| `verbose`            | Controls the amount of output during training                               |\n| `n_jobs`             | Number of parallel jobs (`-1` uses all cores)                               |\n| `refit`              | If `True`, refits the best estimator on the whole dataset                   |\n| `return_train_score` | If `True`, also returns training scores                                     |","metadata":{}},{"cell_type":"markdown","source":"\n\n## K-Fold Cross-Validation\n\n**K-Fold Cross-Validation** is a technique to evaluate the performance of a machine learning model by splitting the dataset into **K equal-sized folds**.\n\n### How It Works:\n\n1. The dataset is divided into **K folds** (subsets).\n2. For each fold:\n\n   * One fold is used as the **validation set**.\n   * The remaining $K - 1$ folds are used for **training**.\n3. This process repeats **K times**, each time with a different fold used for validation.\n4. The performance metric is **averaged** over the K iterations.\n\n\n### Average Performance\n\n\n$$\n\\text{CV Score} = \\frac{1}{K} \\sum_{i=1}^{K} \\text{Score}_i\n$$\n\n\n###  Common Choice:\n\n* $K = 5$ or $K = 10$ are most commonly used in practice.","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [3, 5, 10, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2', None],\n    'splitter': ['best', 'random']\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_tree = GridSearchCV(estimator = model, param_grid = param_grid, cv = 10, scoring = 'f1_weighted', n_jobs = -1)\n\ngrid_tree.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2025-06-19T10:31:29.292892Z","iopub.execute_input":"2025-06-19T10:31:29.293439Z","iopub.status.idle":"2025-06-19T10:31:54.730767Z","shell.execute_reply.started":"2025-06-19T10:31:29.293408Z","shell.execute_reply":"2025-06-19T10:31:54.729875Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [3, 5, 10, None],\n                         'max_features': ['sqrt', 'log2', None],\n                         'min_samples_leaf': [1, 2, 4],\n                         'min_samples_split': [2, 5, 10],\n                         'splitter': ['best', 'random']},\n             scoring='f1_weighted')","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n                         &#x27;max_depth&#x27;: [3, 5, 10, None],\n                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n             scoring=&#x27;f1_weighted&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n                         &#x27;max_depth&#x27;: [3, 5, 10, None],\n                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n             scoring=&#x27;f1_weighted&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"print(\"Best parameters:\", grid_tree.best_params_)\nprint(\"Best F1 Score (CV):\", grid_tree.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:54.731739Z","iopub.execute_input":"2025-06-19T10:31:54.731943Z","iopub.status.idle":"2025-06-19T10:31:54.736649Z","shell.execute_reply.started":"2025-06-19T10:31:54.731928Z","shell.execute_reply":"2025-06-19T10:31:54.735784Z"}},"outputs":[{"name":"stdout","text":"Best parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\nBest F1 Score (CV): 0.9440877452974199\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"y_pred_grid = grid_tree.predict(x_test)\n\nprint(\"Weighted F1 score: \", f1_score(y_test, y_pred_grid, average = 'weighted'))\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred_grid))\nprint(classification_report(y_test, y_pred_grid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:54.737427Z","iopub.execute_input":"2025-06-19T10:31:54.737811Z","iopub.status.idle":"2025-06-19T10:31:54.761150Z","shell.execute_reply.started":"2025-06-19T10:31:54.737708Z","shell.execute_reply":"2025-06-19T10:31:54.760383Z"}},"outputs":[{"name":"stdout","text":"Weighted F1 score:  0.9211816744528192\nAccuracy score:  0.945010183299389\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       929\n           1       0.33      0.02      0.04        53\n\n    accuracy                           0.95       982\n   macro avg       0.64      0.51      0.50       982\nweighted avg       0.91      0.95      0.92       982\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"\n\n## `RandomForestClassifier`\n\n`RandomForestClassifier` is an **ensemble learning method** in scikit-learn that builds a **\"forest\" of decision trees** and aggregates their predictions to improve classification performance and reduce overfitting.\n\nIt’s based on the **bagging (Bootstrap Aggregation)** technique and introduces randomness in both:\n\n* **Data selection** (via bootstrapping)\n* **Feature selection** (random subset at each split)\n\n\n\n### How It Works\n\n1. **Bootstrapping**:\n\n   * Random samples (with replacement) are drawn from the dataset to train each tree.\n\n2. **Random Feature Selection**:\n\n   * At each node, only a random subset of features is considered for splitting.\n\n3. **Ensemble Prediction**:\n\n   * Final prediction is made by **majority voting** across all trees (for classification).\n\n\n\n### Mathematical Representation\n\nLet each tree be $T_i$, trained on a bootstrap sample:\n\n$$\n\\hat{y} = \\text{majority vote}(T_1(x), T_2(x), ..., T_n(x))\n$$\n\n### Key Parameters\n\n| Parameter           | Description                                                       |\n| ------------------- | ----------------------------------------------------------------- |\n| `n_estimators`      | Number of trees in the forest (default: 100)                      |\n| `criterion`         | Splitting metric: `'gini'` (default) or `'entropy'`               |\n| `max_depth`         | Maximum depth of each tree                                        |\n| `min_samples_split` | Minimum number of samples to split an internal node               |\n| `min_samples_leaf`  | Minimum number of samples required at a leaf node                 |\n| `max_features`      | Number of features to consider when looking for the best split    |\n| `bootstrap`         | Whether to use bootstrap sampling (default: `True`)               |\n| `oob_score`         | Use out-of-bag samples to estimate performance (default: `False`) |\n| `random_state`      | Seed for reproducibility                                          |\n\n\n\n### Advantages\n\n* High accuracy\n* Robust to overfitting\n* Works well with missing and categorical data\n* Handles large feature spaces and datasets efficiently\n\n\n### Disadvantages\n\n* Less interpretable than a single decision tree\n* Can be slow for very large datasets with many trees\n* Larger memory footprint","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(n_estimators = 500, random_state = 42)\nforest.fit(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:54.761881Z","iopub.execute_input":"2025-06-19T10:31:54.762470Z","iopub.status.idle":"2025-06-19T10:31:56.557525Z","shell.execute_reply.started":"2025-06-19T10:31:54.762439Z","shell.execute_reply":"2025-06-19T10:31:56.556834Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(n_estimators=500, random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"y_pred_forest = model.predict(x_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_forest))\nprint(\"Weighted F1 score: \", f1_score(y_test, y_pred_forest, average = 'weighted'))\nprint(classification_report(y_test, y_pred_forest))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:56.558118Z","iopub.execute_input":"2025-06-19T10:31:56.558279Z","iopub.status.idle":"2025-06-19T10:31:56.574359Z","shell.execute_reply.started":"2025-06-19T10:31:56.558265Z","shell.execute_reply":"2025-06-19T10:31:56.573442Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9164969450101833\nWeighted F1 score:  0.9132676560974813\n              precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96       929\n           1       0.18      0.15      0.16        53\n\n    accuracy                           0.92       982\n   macro avg       0.56      0.56      0.56       982\nweighted avg       0.91      0.92      0.91       982\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"param_grid = {\n    'n_estimators': [100,200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2,5],\n    'min_samples_leaf': [1,2],\n    'max_features': ['sqrt', 'log2']\n}\n\ngrid_random_forest = GridSearchCV(RandomForestClassifier(random_state=42),\n                    param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n\ngrid_random_forest.fit(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:31:56.575366Z","iopub.execute_input":"2025-06-19T10:31:56.575687Z","iopub.status.idle":"2025-06-19T10:32:51.243605Z","shell.execute_reply.started":"2025-06-19T10:31:56.575662Z","shell.execute_reply":"2025-06-19T10:32:51.242843Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n             param_grid={'max_depth': [None, 10, 20],\n                         'max_features': ['sqrt', 'log2'],\n                         'min_samples_leaf': [1, 2],\n                         'min_samples_split': [2, 5],\n                         'n_estimators': [100, 200]},\n             scoring='accuracy')","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [1, 2],\n                         &#x27;min_samples_split&#x27;: [2, 5],\n                         &#x27;n_estimators&#x27;: [100, 200]},\n             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [1, 2],\n                         &#x27;min_samples_split&#x27;: [2, 5],\n                         &#x27;n_estimators&#x27;: [100, 200]},\n             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"print(\"Best params:\", grid_random_forest.best_params_)\nprint(\"Best score:\", grid_random_forest.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:32:51.244364Z","iopub.execute_input":"2025-06-19T10:32:51.244632Z","iopub.status.idle":"2025-06-19T10:32:51.248979Z","shell.execute_reply.started":"2025-06-19T10:32:51.244616Z","shell.execute_reply":"2025-06-19T10:32:51.248135Z"}},"outputs":[{"name":"stdout","text":"Best params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\nBest score: 0.960529975202995\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"y_pred_forest_grid = grid_random_forest.predict(x_test)\n\nprint(\"Weighted F1 score: \", f1_score(y_test, y_pred_forest_grid, average = 'weighted'))\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred_forest_grid))\nprint(classification_report(y_test, y_pred_forest_grid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:32:51.251880Z","iopub.execute_input":"2025-06-19T10:32:51.252090Z","iopub.status.idle":"2025-06-19T10:32:51.291286Z","shell.execute_reply.started":"2025-06-19T10:32:51.252075Z","shell.execute_reply":"2025-06-19T10:32:51.290347Z"}},"outputs":[{"name":"stdout","text":"Weighted F1 score:  0.9197911970678917\nAccuracy score:  0.9460285132382892\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       929\n           1       0.00      0.00      0.00        53\n\n    accuracy                           0.95       982\n   macro avg       0.47      0.50      0.49       982\nweighted avg       0.89      0.95      0.92       982\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## `SVC` – Support Vector Classifier (scikit-learn)\n\n`SVC` stands for **Support Vector Classifier**, an implementation of the **Support Vector Machine (SVM)** algorithm used for **binary and multi-class classification**.\n\nIt works by finding the **optimal hyperplane** that maximally separates classes in the feature space.\n\n\n### Core Idea\n\nSVM aims to:\n\n* Find a decision boundary (hyperplane) with the **maximum margin** between different classes.\n* Use **support vectors**, the closest points to the hyperplane, to define that boundary.\n\n#### Margin Maximization Formula:\n\nThe goal is to minimize:\n\n$$\n\\frac{1}{2} \\lVert \\mathbf{w} \\rVert^2\n$$\n\nSubject to:\n\n$$\ny_i(\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1\n$$\n\nWhere:\n\n* $\\mathbf{w}$ = weights (normal vector to the hyperplane)\n* $b$ = bias\n* $y_i$ = class label (+1 or -1)\n* $\\mathbf{x}_i$ = feature vector\n\n\n### Kernel Trick\n\nWhen data is **not linearly separable**, SVM uses **kernels** to project it into a higher-dimensional space where it is separable.\n\nCommon kernels:\n\n* `'linear'` — for linear problems\n* `'rbf'` (default) — Radial Basis Function (nonlinear)\n* `'poly'` — Polynomial\n* `'sigmoid'` — Neural network-like\n\n### Important Parameters\n\n| Parameter      | Description                                                           |\n| -------------- | --------------------------------------------------------------------- |\n| `C`            | Regularization parameter (controls margin width vs misclassification) |\n| `kernel`       | Type of kernel function: `'linear'`, `'poly'`, `'rbf'`, `'sigmoid'`   |\n| `gamma`        | Kernel coefficient for `'rbf'`, `'poly'`, `'sigmoid'` kernels         |\n| `degree`       | Degree of the polynomial kernel                                       |\n| `probability`  | Whether to enable probability estimates (`True` adds overhead)        |\n| `class_weight` | Adjust weights to handle imbalanced data (e.g., `'balanced'`)         |\n\n\n### Advantages\n\n* Works well for high-dimensional spaces\n* Effective when number of features > number of samples\n* Flexible with kernel functions\n* Robust to overfitting in many cases\n\n### Disadvantages\n\n* Not efficient on large datasets\n* Requires proper scaling of features\n* Sensitive to choice of kernel and hyperparameters","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nmodel_vec = SVC(kernel = 'rbf', C=1.0, gamma = 'scale', random_state = 42)\nmodel_vec.fit(x_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:32:51.292349Z","iopub.execute_input":"2025-06-19T10:32:51.292708Z","iopub.status.idle":"2025-06-19T10:32:51.389884Z","shell.execute_reply.started":"2025-06-19T10:32:51.292679Z","shell.execute_reply":"2025-06-19T10:32:51.389136Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"SVC(random_state=42)","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"y_pred_vec = model_vec.predict(x_test)\n\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred_vec))\nprint(\"Weighted F1 score: \", f1_score(y_test, y_pred_vec, average = 'weighted'))\nprint(classification_report(y_test, y_pred_vec))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:32:51.390614Z","iopub.execute_input":"2025-06-19T10:32:51.390894Z","iopub.status.idle":"2025-06-19T10:32:51.436328Z","shell.execute_reply.started":"2025-06-19T10:32:51.390869Z","shell.execute_reply":"2025-06-19T10:32:51.435563Z"}},"outputs":[{"name":"stdout","text":"Accuracy score:  0.9460285132382892\nWeighted F1 score:  0.9197911970678917\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       929\n           1       0.00      0.00      0.00        53\n\n    accuracy                           0.95       982\n   macro avg       0.47      0.50      0.49       982\nweighted avg       0.89      0.95      0.92       982\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"param_grid = {\n    'C': [0.1, 1, 10],\n    'kernel': ['rbf'],\n    'gamma': ['auto']\n}\n\ngrid_vec = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\ngrid_vec.fit(x_train, y_train)\n\nprint(\"Best Parameters:\", grid_vec.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:42:51.440038Z","iopub.execute_input":"2025-06-19T10:42:51.440560Z","iopub.status.idle":"2025-06-19T10:42:58.215198Z","shell.execute_reply.started":"2025-06-19T10:42:51.440541Z","shell.execute_reply":"2025-06-19T10:42:58.214461Z"}},"outputs":[{"name":"stdout","text":"Best Parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"grid_vec_pred = grid_vec.predict(x_test)\n\nprint(\"Accuracy score: \", accuracy_score(y_test, grid_vec_pred))\nprint(\"Weighted F1 score: \", f1_score(y_test, grid_vec_pred, average = 'weighted'))\nprint(classification_report(y_test, grid_vec_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:43:01.603413Z","iopub.execute_input":"2025-06-19T10:43:01.603682Z","iopub.status.idle":"2025-06-19T10:43:01.729396Z","shell.execute_reply.started":"2025-06-19T10:43:01.603665Z","shell.execute_reply":"2025-06-19T10:43:01.728458Z"}},"outputs":[{"name":"stdout","text":"Accuracy score:  0.9460285132382892\nWeighted F1 score:  0.9197911970678917\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       929\n           1       0.00      0.00      0.00        53\n\n    accuracy                           0.95       982\n   macro avg       0.47      0.50      0.49       982\nweighted avg       0.89      0.95      0.92       982\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## `KNeighborsClassifier` – K-Nearest Neighbors (KNN)\n\n`KNeighborsClassifier` is a **simple, intuitive**, and widely used classification algorithm based on **similarity**. It classifies a new data point by looking at the **'k' closest training examples** and assigning the most common class among them.\n\n\n### How It Works\n\n1. Choose a value of **$k$** (number of neighbors).\n2. Calculate the **distance** (e.g., Euclidean) from the new point to all training points.\n3. Select the **k nearest neighbors**.\n4. Assign the class that is **most common among those neighbors**.\n\n\n### Distance Metric\n\nBy default, KNN uses **Euclidean distance**:\n\n$$\n\\text{distance} = \\sqrt{ \\sum_{i=1}^{n} (x_i - y_i)^2 }\n$$\n\nYou can also use:\n\n* **Manhattan** distance\n* **Minkowski** distance\n* Custom distance metrics\n\n### Important Parameters\n\n| Parameter     | Description                                                                           |\n| ------------- | ------------------------------------------------------------------------------------- |\n| `n_neighbors` | Number of neighbors to use (the \"k\" in KNN)                                           |\n| `weights`     | `'uniform'` (all neighbors equal) or `'distance'` (closer neighbors have more weight) |\n| `metric`      | Distance function to use (`'euclidean'`, `'manhattan'`, `'minkowski'`, etc.)          |\n| `p`           | Power parameter for Minkowski metric (p=2 = Euclidean, p=1 = Manhattan)               |\n| `algorithm`   | Search algorithm: `'auto'`, `'ball_tree'`, `'kd_tree'`, `'brute'`                     |\n\n\n### Advantages\n\n* Simple to implement and understand\n* No training phase (instance-based)\n* Naturally handles multi-class classification\n\n### Disadvantages\n\n* Slow with large datasets (prediction requires distance computation for all points)\n* Sensitive to irrelevant or scaled features\n* Doesn’t work well in high-dimensional spaces (**curse of dimensionality**)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(x_train)\nX_test_scaled = scaler.transform(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:37:29.902044Z","iopub.execute_input":"2025-06-19T10:37:29.902652Z","iopub.status.idle":"2025-06-19T10:37:29.914312Z","shell.execute_reply.started":"2025-06-19T10:37:29.902632Z","shell.execute_reply":"2025-06-19T10:37:29.913489Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\nknn.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:38:49.078220Z","iopub.execute_input":"2025-06-19T10:38:49.078873Z","iopub.status.idle":"2025-06-19T10:38:49.086440Z","shell.execute_reply.started":"2025-06-19T10:38:49.078853Z","shell.execute_reply":"2025-06-19T10:38:49.085629Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"KNeighborsClassifier()","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"y_pred = knn.predict(X_test_scaled)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:38:51.153288Z","iopub.execute_input":"2025-06-19T10:38:51.154145Z","iopub.status.idle":"2025-06-19T10:38:51.257377Z","shell.execute_reply.started":"2025-06-19T10:38:51.154118Z","shell.execute_reply":"2025-06-19T10:38:51.256414Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.945010183299389\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       929\n           1       0.40      0.04      0.07        53\n\n    accuracy                           0.95       982\n   macro avg       0.67      0.52      0.52       982\nweighted avg       0.92      0.95      0.92       982\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Define the parameter grid\nparam_grid = {\n    'n_neighbors': [3, 5, 7, 9, 11],\n    'weights': ['uniform', 'distance'],\n    'p': [1, 2] \n}\n\n# Initialize the model\nknn = KNeighborsClassifier()\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(\n    estimator=knn,\n    param_grid=param_grid,\n    cv=5,\n    scoring='f1_weighted',\n    verbose=1,\n    n_jobs=-1\n)\n\n# Fit to the training data\ngrid_search.fit(X_train_scaled, y_train)\n\n# Best parameters and score\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(\"Best Score:\", grid_search.best_score_)\n\n# Use the best model\nbest_knn = grid_search.best_estimator_\ny_pred = best_knn.predict(X_test_scaled)\n\n# Evaluate\nprint(classification_report(y_test, y_pred))\nprint(\"Accuracy score: \", accuracy_score(y_test, y_pred))\nprint(\"Weighted F1 score: \", f1_score(y_test, y_pred, average='weighted'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T10:41:49.418538Z","iopub.execute_input":"2025-06-19T10:41:49.418816Z","iopub.status.idle":"2025-06-19T10:41:52.960690Z","shell.execute_reply.started":"2025-06-19T10:41:49.418798Z","shell.execute_reply":"2025-06-19T10:41:52.959714Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 20 candidates, totalling 100 fits\nBest Parameters: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\nBest Score: 0.942258112845894\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       929\n           1       0.40      0.04      0.07        53\n\n    accuracy                           0.95       982\n   macro avg       0.67      0.52      0.52       982\nweighted avg       0.92      0.95      0.92       982\n\nAccuracy score:  0.945010183299389\nWeighted F1 score:  0.9229481980051685\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}